{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2951,
     "status": "ok",
     "timestamp": 1736182719393,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "usWcdmOr7GAH",
    "outputId": "a86d99b8-2e58-408a-db5c-79790340fab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-groq langchain-experimental langchain-google-genai neo4j tiktoken yfiles_jupyter_graphs PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8EzdaTJFTbx"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKkxxyasFWPh"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SksHz3Q356JQ"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
    "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCEgNy7LFXS4"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymZquwggFaNr"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nitfT-ktFaQQ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzOPupw0FaSy"
   },
   "outputs": [],
   "source": [
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6kjt1HkFaVZ"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IR5TLMjpFhE-"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSgOwI9SFhHr"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiKFX23n4tl3"
   },
   "outputs": [],
   "source": [
    "#paste your neo4j uri, username and password here\n",
    "NEO4J_URI=\"\"\n",
    "NEO4J_USERNAME=\"\"\n",
    "NEO4J_PASSWORD=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHiqiwau7Tat"
   },
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"NEO4J_URI\"] = NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"] = NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"] = NEO4J_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpIPagYu6BAp"
   },
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xzi4bRD6Bx9"
   },
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbFfEq-MfQVI"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCI3R3_WfsLU"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"your/pdf/path\")\n",
    "raw_documents = []\n",
    "async for page in loader.alazy_load():\n",
    "    raw_documents.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1736182162773,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "ACWeDt0O7yc2",
    "outputId": "3959db3f-1877-4bef-e2be-4da996e25fe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1736183326347,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "skFy3n30732l",
    "outputId": "62619276-eb4b-4539-cee2-8529c5061296"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/content/12. Fine-Tuning Generation Models _ Hands-On Large Language Models.pdf', 'page': 0}, page_content='Chapter 12. Fine-Tuning GenerationModels\\nIn this chapter, we will take a pretrained text generation model and go\\nover the process of fine-tuning it. This fine-tuning step is key in producing\\nhigh-quality models and an important tool in our toolbox to adapt a\\nmodel to a specific desired behavior. Fine-tuning allows us to adapt a\\nmodel to a specific dataset or domain.\\nThroughout this chapter, we will guide you among the two most common\\nmethods for fine-tuning text generation models, supervised fine-tuning\\nand preference tuning. We will explore the transformative potential of\\nfine-tuning pretrained text generation models to make them more effec-\\ntive tools for your application.\\nThe Three LLM Training Steps:Pretraining, Supervised Fine-Tuning,and Preference Tuning\\nThere are three common steps that lead to creating a high-quality LLM:\\n1. Language modeling\\nThe first step in creating a high-quality LLM is to pretrain it on one\\nor more massive text datasets (Figure\\xa012-1). During training, it at-\\ntempts to predict the next token to accurately learn linguistic and\\nsemantic representations found in the text. As we saw before in\\nChapters 3 and 11, this is called language modeling and is a self-su-\\npervised method.\\nThis produces a base model, also commonly referred to as a pre-\\ntrained or foundation model. Base models are a key artifact of the\\ntraining process but are harder for the end user to deal with. This\\nis why the next step is important.\\nFigure 12-1. During language modeling, the LLM aims to predict the next token based onan input. This is a process without labels.\\n2. Fine-tuning 1 (supervised fine-tuning)\\nLLMs are more useful if they respond well to instructions and try\\nto follow them. When humans ask the model to write an article,\\nthey expect the model to generate the article and not list other in-\\nstructions for example (which is what a base model might do).\\nWith supervised fine-tuning (SFT), we can adapt the base model to\\nfollow instructions. During this fine-tuning process, the parameters\\nof the base model are updated to be more in line with our target\\ntask, like following instructions. Like a pretrained model, it is\\ntrained using next-token prediction but instead of only predicting\\nthe next token, it does so based on a user input (Figure\\xa012-2).')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ChZ008I6paW"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(raw_documents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMh_IpRb78rs"
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mer51fZA9pa1"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZP64uFM9vLk"
   },
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1736183320714,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "3Nwjd5yR92VE",
    "outputId": "63b1a65b-32aa-4fb8-89c2-5c849261ab3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GraphDocument(nodes=[Node(id='Chapter 12', type='Chapter', properties={}), Node(id='Pretrained Text Generation Model', type='Model', properties={}), Node(id='Fine-Tuning', type='Process', properties={}), Node(id='High-Quality Models', type='Models', properties={}), Node(id='Supervised Fine-Tuning', type='Fine-tuning', properties={}), Node(id='Preference Tuning', type='Fine-tuning', properties={}), Node(id='Language Modeling', type='Step', properties={}), Node(id='Base Models', type='Models', properties={}), Node(id='End User', type='User', properties={}), Node(id='Instructions', type='Concept', properties={}), Node(id='Tokens', type='Unit', properties={}), Node(id='Linguistic And Semantic Representations', type='Representations', properties={}), Node(id='Figure 12-1', type='Figure', properties={})], relationships=[Relationship(source=Node(id='Chapter 12', type='Chapter', properties={}), target=Node(id='Pretrained Text Generation Model', type='Model', properties={}), type='CONTAINS', properties={}), Relationship(source=Node(id='Pretrained Text Generation Model', type='Model', properties={}), target=Node(id='Fine-Tuning', type='Process', properties={}), type='REQUIRES', properties={}), Relationship(source=Node(id='Fine-Tuning', type='Process', properties={}), target=Node(id='High-Quality Models', type='Models', properties={}), type='PRODUCES', properties={}), Relationship(source=Node(id='Fine-Tuning', type='Process', properties={}), target=Node(id='Supervised Fine-Tuning', type='Fine-tuning', properties={}), type='INCLUDES', properties={}), Relationship(source=Node(id='Fine-Tuning', type='Process', properties={}), target=Node(id='Preference Tuning', type='Fine-tuning', properties={}), type='INCLUDES', properties={}), Relationship(source=Node(id='Language Modeling', type='Step', properties={}), target=Node(id='High-Quality Models', type='Models', properties={}), type='REQUIRES', properties={}), Relationship(source=Node(id='High-Quality Models', type='Models', properties={}), target=Node(id='Base Models', type='Models', properties={}), type='IS_A', properties={}), Relationship(source=Node(id='End User', type='User', properties={}), target=Node(id='Instructions', type='Concept', properties={}), type='INTERACTS_WITH', properties={}), Relationship(source=Node(id='Base Models', type='Models', properties={}), target=Node(id='Instructions', type='Concept', properties={}), type='HAS_DIFFICULTY_WITH', properties={}), Relationship(source=Node(id='Supervised Fine-Tuning', type='Fine-tuning', properties={}), target=Node(id='Instructions', type='Concept', properties={}), type='ADAPTS', properties={}), Relationship(source=Node(id='Figure 12-1', type='Figure', properties={}), target=Node(id='Language Modeling', type='Step', properties={}), type='ILLUSTRATES', properties={}), Relationship(source=Node(id='Language Modeling', type='Step', properties={}), target=Node(id='Tokens', type='Unit', properties={}), type='PROCESSES', properties={}), Relationship(source=Node(id='Language Modeling', type='Step', properties={}), target=Node(id='Linguistic And Semantic Representations', type='Representations', properties={}), type='LEARNS', properties={})], source=Document(metadata={'source': '/content/12. Fine-Tuning Generation Models _ Hands-On Large Language Models.pdf', 'page': 0, 'id': '5d1c03b26726152923e8b9d1da650e4e'}, page_content='Chapter 12. Fine-Tuning GenerationModels\\nIn this chapter, we will take a pretrained text generation model and go\\nover the process of fine-tuning it. This fine-tuning step is key in producing\\nhigh-quality models and an important tool in our toolbox to adapt a\\nmodel to a specific desired behavior. Fine-tuning allows us to adapt a\\nmodel to a specific dataset or domain.\\nThroughout this chapter, we will guide you among the two most common\\nmethods for fine-tuning text generation models, supervised fine-tuning\\nand preference tuning. We will explore the transformative potential of\\nfine-tuning pretrained text generation models to make them more effec-\\ntive tools for your application.\\nThe Three LLM Training Steps:Pretraining, Supervised Fine-Tuning,and Preference Tuning\\nThere are three common steps that lead to creating a high-quality LLM:\\n1. Language modeling\\nThe first step in creating a high-quality LLM is to pretrain it on one\\nor more massive text datasets (Figure\\xa012-1). During training, it at-\\ntempts to predict the next token to accurately learn linguistic and\\nsemantic representations found in the text. As we saw before in\\nChapters 3 and 11, this is called language modeling and is a self-su-\\npervised method.\\nThis produces a base model, also commonly referred to as a pre-\\ntrained or foundation model. Base models are a key artifact of the\\ntraining process but are harder for the end user to deal with. This\\nis why the next step is important.\\nFigure 12-1. During language modeling, the LLM aims to predict the next token based onan input. This is a process without labels.\\n2. Fine-tuning 1 (supervised fine-tuning)\\nLLMs are more useful if they respond well to instructions and try\\nto follow them. When humans ask the model to write an article,\\nthey expect the model to generate the article and not list other in-\\nstructions for example (which is what a base model might do).\\nWith supervised fine-tuning (SFT), we can adapt the base model to\\nfollow instructions. During this fine-tuning process, the parameters\\nof the base model are updated to be more in line with our target\\ntask, like following instructions. Like a pretrained model,'))]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ib_g3U1d97th"
   },
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rC-4O5FQ99yH"
   },
   "outputs": [],
   "source": [
    "# directly show the graph resulting from the given Cypher query\n",
    "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-91BluK_62t"
   },
   "outputs": [],
   "source": [
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djVL6Gh4_4sV"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ll2WNnO-Ahf"
   },
   "outputs": [],
   "source": [
    "def showGraph(cypher: str = default_cypher):\n",
    "    # create a neo4j session to run queries\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    display(widget)\n",
    "    return widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "aa12cef7dde24ca1b577e045639129e7",
      "8310731ee65d48faa6771b4240d470ae"
     ]
    },
    "executionInfo": {
     "elapsed": 3303,
     "status": "ok",
     "timestamp": 1736182381855,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "kz-O4c0k-C_4",
    "outputId": "27fd5846-c08f-403e-c311-599e9ebc66f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa12cef7dde24ca1b577e045639129e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa12cef7dde24ca1b577e045639129e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "colab": {
        "custom_widget_manager": {
         "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
        }
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHSkb7LeBghn"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuDVi4vHBjXP"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_JloAimBlcK"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"),\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1736182882953,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "e0EXdSStG-Oe",
    "outputId": "cb72d521-7f74-4f5d-a404-63697108e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qksArGKrAvie"
   },
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "# Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx6sfpgRBrs-"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUobRC1wAx-_"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGR6ocjkA0I_"
   },
   "outputs": [],
   "source": [
    "entity_chain = prompt | llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1955,
     "status": "ok",
     "timestamp": 1736183027137,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "xPLkIEmkA2R2",
    "outputId": "befc71b0-b46f-497f-d953-bdb4ba61fe9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entities(names=['RLHF'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_chain.invoke({\"question\": \"What is RLHF?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpbOzL5BA6hW"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gHCkvGKA86t"
   },
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjPkmFJbA_lv"
   },
   "outputs": [],
   "source": [
    "# Fulltext index query\n",
    "def structured_retriever(question: str) -> str:\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1468,
     "status": "ok",
     "timestamp": 1736183058876,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "nIla9QpzBA8u",
    "outputId": "76df74e3-9bd7-4eae-b961-c402d35ef665"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(structured_retriever(\"What is RLHF?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zo1QoB_iBDfO"
   },
   "outputs": [],
   "source": [
    "def retriever(question: str):\n",
    "    print(f\"Search query: {question}\")\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "{\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDLnOXBTBFaf"
   },
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
    "in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hozfZicpBG2G"
   },
   "outputs": [],
   "source": [
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9Oi3AEeBIPf"
   },
   "outputs": [],
   "source": [
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXV65bjDBJwO"
   },
   "outputs": [],
   "source": [
    "_search_query = RunnableBranch(\n",
    "    # If input includes chat_history, we condense it with the follow-up question\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | ChatGroq(temperature=0, model_name=\"mixtral-8x7b-32768\")\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # Else, we have no chat history, so just pass through the question\n",
    "    RunnableLambda(lambda x : x[\"question\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuVyoD1iBLgt"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehex9TRGBM4m"
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UI6LVwkpBOOA"
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "executionInfo": {
     "elapsed": 2351,
     "status": "ok",
     "timestamp": 1736183121336,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "GZAq-jz3BOrn",
    "outputId": "22c36d6a-bd77-4663-8656-bda9323ff1d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: What is RLHF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"RLHF, or Reinforcement Learning with Human Feedback, is a process that aligns a language model's behavior with human expectations. It does this by using human evaluators to score the quality of the model's generations, and then updating the model based on these scores. If the score is high, the model is encouraged to generate more like this type of generation. If the score is low, the model is discouraged from generating such outputs. This process helps to ensure that the model's outputs align with human preferences.\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is RLHF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "executionInfo": {
     "elapsed": 2593,
     "status": "ok",
     "timestamp": 1736183266217,
     "user": {
      "displayName": "Hardik Negi",
      "userId": "12440130097247728572"
     },
     "user_tz": -330
    },
    "id": "b8bO9V_MIBZ5",
    "outputId": "71c85efa-df32-4a32-99fc-1790d5e19dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: What is the concept of Training a Model without Reward Feedback?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Training No Reward Model refers to a method of aligning a language model's behavior with human preferences, without using a separate reward model. Instead, it uses a copy of the language model itself as a reference to judge the quality of generations. During training, it calculates the shift in probabilities between the reference and trainable models for accepted and rejected generations, optimizing the likelihood of accepted generations over rejected ones. This method is an alternative to Proximal Policy Optimization (PPO) and can be more cost-effective as it doesn't require training two models.\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is Training No Reward Model?\",\n",
    "        \"chat_history\": [(\"What is RLHF?\", \"RLHF, or Reinforcement Learning with Human Feedback, is a process that aligns a language model's behavior with human expectations. It does this by using human evaluators to score the quality of the model's generations, and then updating the model based on these scores. If the score is high, the model is encouraged to generate more like this type of generation. If the score is low, the model is discouraged from generating such outputs. This process helps to ensure that the model's outputs align with human preferences.\")],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyIlAGROIUKC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "8310731ee65d48faa6771b4240d470ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": "800px",
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "aa12cef7dde24ca1b577e045639129e7": {
     "model_module": "yfiles-jupyter-graphs",
     "model_module_version": "^1.10.1",
     "model_name": "GraphModel",
     "state": {
      "_context_pane_mapping": [
       {
        "id": "Neighborhood",
        "title": "Neighborhood"
       },
       {
        "id": "Data",
        "title": "Data"
       },
       {
        "id": "Search",
        "title": "Search"
       },
       {
        "id": "About",
        "title": "About"
       }
      ],
      "_data_importer": "neo4j",
      "_directed": true,
      "_dom_classes": [],
      "_edges": [
       {
        "color": "#673AB7",
        "directed": true,
        "end": 23,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 9,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 23,
        "id": 6919850096687317000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 10,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 23,
        "id": 6922101896501002000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 11,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 24,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 12,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 25,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 13,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 26,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 14,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 27,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 15,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 28,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 16,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 29,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 17,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 30,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 18,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 31,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 19,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 32,
        "id": 6917598296873632000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 20,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 32,
        "id": 6919850096687317000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 21,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 32,
        "id": 6922101896501002000,
        "label": "AUTHORED",
        "properties": {
         "label": "AUTHORED"
        },
        "start": 22,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 34,
        "id": 1152969883118469000,
        "label": "CONTAINS",
        "properties": {
         "label": "CONTAINS"
        },
        "start": 33,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 83,
        "id": 1153095227444035600,
        "label": "REQUIRES",
        "properties": {
         "label": "REQUIRES"
        },
        "start": 34,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 36,
        "id": 1152927002164985900,
        "label": "IS_A",
        "properties": {
         "label": "IS_A"
        },
        "start": 35,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 85,
        "id": 1153109521095196700,
        "label": "HAS_DIFFICULTY_WITH",
        "properties": {
         "label": "HAS_DIFFICULTY_WITH"
        },
        "start": 36,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 85,
        "id": 1153108421583569000,
        "label": "INTERACTS_WITH",
        "properties": {
         "label": "INTERACTS_WITH"
        },
        "start": 37,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 74,
        "id": 1152970982630097000,
        "label": "ILLUSTRATES",
        "properties": {
         "label": "ILLUSTRATES"
        },
        "start": 40,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 86,
        "id": 1152933599234752500,
        "label": "BASED_ON",
        "properties": {
         "label": "BASED_ON"
        },
        "start": 41,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 44,
        "id": 1153116118164963300,
        "label": "FINE-TUNING",
        "properties": {
         "label": "FINE-TUNING"
        },
        "start": 43,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 76,
        "id": 1153094127932407800,
        "label": "INPUT",
        "properties": {
         "label": "INPUT"
        },
        "start": 45,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 72,
        "id": 1153094127932407800,
        "label": "INPUT",
        "properties": {
         "label": "INPUT"
        },
        "start": 46,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 76,
        "id": 1153094127932407800,
        "label": "INPUT",
        "properties": {
         "label": "INPUT"
        },
        "start": 47,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 76,
        "id": 1153117217676591000,
        "label": "OUTPUT",
        "properties": {
         "label": "OUTPUT"
        },
        "start": 48,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 48,
        "id": 1153118317188219000,
        "label": "IS",
        "properties": {
         "label": "IS"
        },
        "start": 49,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 72,
        "id": 1152970982630097000,
        "label": "ILLUSTRATES",
        "properties": {
         "label": "ILLUSTRATES"
        },
        "start": 50,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 44,
        "id": 1153119416699846700,
        "label": "DEMONSTRATES",
        "properties": {
         "label": "DEMONSTRATES"
        },
        "start": 51,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 76,
        "id": 1152970982630097000,
        "label": "ILLUSTRATES",
        "properties": {
         "label": "ILLUSTRATES"
        },
        "start": 52,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 76,
        "id": 1152970982630097000,
        "label": "ILLUSTRATES",
        "properties": {
         "label": "ILLUSTRATES"
        },
        "start": 53,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 55,
        "id": 1153120516211474400,
        "label": "CAN_USE",
        "properties": {
         "label": "CAN_USE"
        },
        "start": 54,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 56,
        "id": 1153121615723102200,
        "label": "IS_A_TYPE_OF",
        "properties": {
         "label": "IS_A_TYPE_OF"
        },
        "start": 55,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 57,
        "id": 1152930300699869200,
        "label": "USES",
        "properties": {
         "label": "USES"
        },
        "start": 56,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 58,
        "id": 1155182100513554400,
        "label": "USES",
        "properties": {
         "label": "USES"
        },
        "start": 56,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#673AB7",
        "directed": true,
        "end": 60,
        "id": 1153122715234730000,
        "label": "APPLIES",
        "properties": {
         "label": "APPLIES"
        },
        "start": 56,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 59,
        "id": 1153121615723102200,
        "label": "IS_A_TYPE_OF",
        "properties": {
         "label": "IS_A_TYPE_OF"
        },
        "start": 58,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 56,
        "id": 1152939096792891400,
        "label": "ALTERNATIVE_TO",
        "properties": {
         "label": "ALTERNATIVE_TO"
        },
        "start": 61,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 71,
        "id": 1152969883118469000,
        "label": "CONTAINS",
        "properties": {
         "label": "CONTAINS"
        },
        "start": 70,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 72,
        "id": 1155221682932154400,
        "label": "CONTAINS",
        "properties": {
         "label": "CONTAINS"
        },
        "start": 70,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#CDDC39",
        "directed": true,
        "end": 73,
        "id": 1157473482745839600,
        "label": "CONTAINS",
        "properties": {
         "label": "CONTAINS"
        },
        "start": 70,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 85,
        "id": 1152937997281263600,
        "label": "ADAPTS",
        "properties": {
         "label": "ADAPTS"
        },
        "start": 72,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9C27B0",
        "directed": true,
        "end": 86,
        "id": 1153051246978924500,
        "label": "AIMS_TO_PREDICT",
        "properties": {
         "label": "AIMS_TO_PREDICT"
        },
        "start": 72,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 44,
        "id": 6917721442175943000,
        "label": "INVOLVES",
        "properties": {
         "label": "INVOLVES"
        },
        "start": 72,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#2196F3",
        "directed": true,
        "end": 44,
        "id": 6919973241989628000,
        "label": "INVOLVES",
        "properties": {
         "label": "INVOLVES"
        },
        "start": 73,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#4CAF50",
        "directed": true,
        "end": 39,
        "id": 1153079834281246700,
        "label": "LEARNS",
        "properties": {
         "label": "LEARNS"
        },
        "start": 74,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#9E9E9E",
        "directed": true,
        "end": 35,
        "id": 1153095227444035600,
        "label": "REQUIRES",
        "properties": {
         "label": "REQUIRES"
        },
        "start": 74,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#F44336",
        "directed": true,
        "end": 38,
        "id": 1153110620606824400,
        "label": "PROCESSES",
        "properties": {
         "label": "PROCESSES"
        },
        "start": 74,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 84,
        "id": 1152929201188241400,
        "label": "TRAINED_ON",
        "properties": {
         "label": "TRAINED_ON"
        },
        "start": 75,
        "styles": {},
        "thickness_factor": 1
       },
       {
        "color": "#607D8B",
        "directed": true,
        "end": 74,
        "id": 1152930300699869200,
        "label": "USES",
        "properties": {
         "label": "USES"
        },
        "start": 75,
        "styles": {},
        "thickness_factor": 1
       }
      ],
      "_graph_layout": {},
      "_highlight": [],
      "_license": {},
      "_model_module": "yfiles-jupyter-graphs",
      "_model_module_version": "^1.10.1",
      "_model_name": "GraphModel",
      "_neighborhood": {},
      "_nodes": [
       {
        "color": "#2196F3",
        "id": 9,
        "label": "Stephanie Lin",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Stephanie Lin",
         "label": "Person:__Entity__",
         "uuid": "dcf200b9-2a13-491d-9233-4993920c376d"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 23,
        "label": "Truthfulqa: Measuring How Models Mimic Human Falsehoods",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Truthfulqa: Measuring How Models Mimic Human Falsehoods",
         "label": "__Entity__",
         "uuid": "bd190444-e6b8-4fa5-8215-23f4f1f8c016"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 10,
        "label": "Jacob Hilton",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Jacob Hilton",
         "label": "Person:__Entity__",
         "uuid": "0a1951bb-440d-4e56-8910-f79608b1f014"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#2196F3",
        "id": 11,
        "label": "Owain Evans",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Owain Evans",
         "label": "Person:__Entity__",
         "uuid": "6ef04f4a-c674-4f47-a2b5-2eb0772be14f"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#2196F3",
        "id": 12,
        "label": "Karl Cobbe",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Karl Cobbe",
         "label": "Person:__Entity__",
         "uuid": "838361b3-5910-4e54-81f2-aa16799b1b08"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 24,
        "label": "Training Verifiers To Solve Math Word Problems",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Training Verifiers To Solve Math Word Problems",
         "label": "__Entity__",
         "uuid": "07ac62e1-ffbb-4681-b4a6-ed19a4330337"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 13,
        "label": "Roman Zellers",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Roman Zellers",
         "label": "Person:__Entity__",
         "uuid": "35b6b44a-aa6c-4a4c-8782-c6ef892b71da"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 25,
        "label": "Hellaswag: Can A Machine Really Finish Your Sentence?",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Hellaswag: Can A Machine Really Finish Your Sentence?",
         "label": "__Entity__",
         "uuid": "db06067a-8341-4357-b161-143d66e091c5"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 14,
        "label": "Mark Chen",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Mark Chen",
         "label": "Person:__Entity__",
         "uuid": "6be477a3-17cf-4bdf-be5f-61a87efd8374"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 26,
        "label": "Evaluating Large Language Models Trained On Code",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Evaluating Large Language Models Trained On Code",
         "label": "__Entity__",
         "uuid": "2816f95d-88e3-4d53-8816-67c91dba69d0"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 15,
        "label": "Lianmin Zheng",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Lianmin Zheng",
         "label": "Person:__Entity__",
         "uuid": "91b51dbc-4c40-4e58-95a4-2cd78dfeef53"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 27,
        "label": "Judging Llm-As-A-Judge With Mt-Bench And Chatbot Arena",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Judging Llm-As-A-Judge With Mt-Bench And Chatbot Arena",
         "label": "__Entity__",
         "uuid": "d25cf0a5-5e52-40a5-8cac-8e88a06c79dc"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 16,
        "label": "Wei-Lin Chiang",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Wei-Lin Chiang",
         "label": "Person:__Entity__",
         "uuid": "ecf50661-89ce-41a6-b67a-0e5d79fc6818"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 28,
        "label": "Chatbot Arena: An Open Platform For Evaluating Llms By Human Preference",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Chatbot Arena: An Open Platform For Evaluating Llms By Human Preference",
         "label": "__Entity__",
         "uuid": "cbb9c3ad-bdf0-45b1-8834-f33063403413"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 17,
        "label": "Mafilyn Strathern",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Mafilyn Strathern",
         "label": "Person:__Entity__",
         "uuid": "fcec25fd-e058-4b67-a508-995b23421c17"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 29,
        "label": "‘Improving Ratings’: Audit In The British University System",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "‘Improving Ratings’: Audit In The British University System",
         "label": "__Entity__",
         "uuid": "1da65b46-10ed-409a-b71c-57c0a1f1c88f"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 18,
        "label": "John Schulman",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "John Schulman",
         "label": "Person:__Entity__",
         "uuid": "3c8aa259-a211-4cf1-af8e-ffb0381e428e"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 30,
        "label": "Proximal Policy Optimization Algorithms",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Proximal Policy Optimization Algorithms",
         "label": "__Entity__",
         "uuid": "483c79a8-dd30-4b48-8b7c-62bd8aae4b16"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 19,
        "label": "Rafael Rafailov",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Rafael Rafailov",
         "label": "Person:__Entity__",
         "uuid": "74b857f3-61b7-4074-a14c-243708864ed3"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 31,
        "label": "Direct Preference Optimization: Your Language Model Is Secretly A Reward Model",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Direct Preference Optimization: Your Language Model Is Secretly A Reward Model",
         "label": "__Entity__",
         "uuid": "3b8e72fd-415e-4886-9e23-143e83778214"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 20,
        "label": "Jiwoo Hong",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Jiwoo Hong",
         "label": "Person:__Entity__",
         "uuid": "13f98188-032f-41d3-a375-d812be9ae15c"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 32,
        "label": "Orpo: Monolithic Preference Optimization Without Reference Model",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Orpo: Monolithic Preference Optimization Without Reference Model",
         "label": "__Entity__",
         "uuid": "5c80a53c-1f0b-42b1-9ec4-66490b8da4d6"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#2196F3",
        "id": 21,
        "label": "Noah Lee",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Noah Lee",
         "label": "Person:__Entity__",
         "uuid": "e39d589b-4b45-4aaa-a156-961da381c954"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#2196F3",
        "id": 22,
        "label": "James Thorne",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "James Thorne",
         "label": "Person:__Entity__",
         "uuid": "312e2c0a-25ef-43bc-8660-bd4858ae85d3"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#F44336",
        "id": 33,
        "label": "Chapter 12",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Chapter 12",
         "label": "Chapter:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#607D8B",
        "id": 34,
        "label": "Pretrained Text Generation Model",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Pretrained Text Generation Model",
         "label": "Model:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       },
       {
        "color": "#673AB7",
        "id": 83,
        "label": "Fine-Tuning",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Fine-Tuning",
         "label": "Technique:__Entity__:Process",
         "uuid": "95d6ad68-1a78-4619-b6d2-070c0456cb99"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#CDDC39",
        "id": 35,
        "label": "High-Quality Models",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "High-Quality Models",
         "label": "Models:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#CDDC39",
        "id": 36,
        "label": "Base Models",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Base Models",
         "label": "Models:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#9E9E9E",
        "id": 85,
        "label": "Instructions",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Instructions",
         "label": "Text:Concept:__Entity__",
         "uuid": "2a0df1c5-81f0-4ac9-9934-1c3598bdd633"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9E9E9E"
       },
       {
        "color": "#9C27B0",
        "id": 37,
        "label": "End User",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "End User",
         "label": "User:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9C27B0"
       },
       {
        "color": "#2196F3",
        "id": 40,
        "label": "Figure 12-1",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Figure 12-1",
         "label": "Figure:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 74,
        "label": "Language Modeling",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Language Modeling",
         "label": "Training_method:Step:Concept:__Entity__",
         "uuid": "b8ce5e5b-1d49-40e7-9aa7-b9753599b0f4"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#F44336",
        "id": 41,
        "label": "Next-Token Prediction",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Next-Token Prediction",
         "label": "Next-token prediction:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#607D8B",
        "id": 86,
        "label": "User Input",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "User Input",
         "label": "User input:Concept:__Entity__",
         "uuid": "5595de7b-b884-48b3-8da9-39c651243a0a"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       },
       {
        "color": "#607D8B",
        "id": 43,
        "label": "Untrained Architecture",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Untrained Architecture",
         "label": "Model:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       },
       {
        "color": "#607D8B",
        "id": 44,
        "label": "Fine-Tuned Model",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Fine-Tuned Model",
         "label": "Model:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       },
       {
        "color": "#673AB7",
        "id": 45,
        "label": "Meaning",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Meaning",
         "label": "Concept:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#CDDC39",
        "id": 76,
        "label": "Base Model",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Base Model",
         "label": "Model:Model_type:__Entity__",
         "uuid": "cf41d183-f7b8-44fd-994e-c0ee2646d829"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#673AB7",
        "id": 46,
        "label": "Instruction",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Instruction",
         "label": "Concept:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#9E9E9E",
        "id": 72,
        "label": "Supervised Fine-Tuning",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Supervised Fine-Tuning",
         "label": "Training_step:Fine-tuning:__Entity__:Process",
         "uuid": "42fce131-80da-4a0c-87cf-3d42315c4236"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9E9E9E"
       },
       {
        "color": "#673AB7",
        "id": 47,
        "label": "Input Phrase",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Input Phrase",
         "label": "Concept:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 48,
        "label": "Next Token",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Next Token",
         "label": "Concept:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#673AB7",
        "id": 49,
        "label": "Prediction",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Prediction",
         "label": "Concept:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#2196F3",
        "id": 50,
        "label": "Figure 12-2",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Figure 12-2",
         "label": "Figure:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#2196F3",
        "id": 51,
        "label": "Figure 12-3",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Figure 12-3",
         "label": "Figure:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#2196F3",
        "id": 52,
        "label": "Figure 12-4",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Figure 12-4",
         "label": "Figure:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#2196F3",
        "id": 53,
        "label": "Figure 12-5",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Figure 12-5",
         "label": "Figure:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#9C27B0",
        "id": 54,
        "label": "Base_Model",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Base_Model",
         "label": "Base_model:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9C27B0"
       },
       {
        "color": "#2196F3",
        "id": 55,
        "label": "Fine_Tuning",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Fine_Tuning",
         "label": "Fine_tuning:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 56,
        "label": "Full_Fine_Tuning",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Full_Fine_Tuning",
         "label": "Full_fine_tuning:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#F44336",
        "id": 57,
        "label": "Labeled_Dataset",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Labeled_Dataset",
         "label": "Labeled_dataset:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#607D8B",
        "id": 58,
        "label": "Instruction_Data",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Instruction_Data",
         "label": "Instruction_data:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       },
       {
        "color": "#673AB7",
        "id": 60,
        "label": "Next_Token_Prediction",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Next_Token_Prediction",
         "label": "Next_token_prediction:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#673AB7"
       },
       {
        "color": "#CDDC39",
        "id": 59,
        "label": "Question_Response_Data",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Question_Response_Data",
         "label": "Question_response_data:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#CDDC39"
       },
       {
        "color": "#9E9E9E",
        "id": 61,
        "label": "Parameter_Efficient_Fine_Tuning",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Parameter_Efficient_Fine_Tuning",
         "label": "Parameter_efficient_fine_tuning:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9E9E9E"
       },
       {
        "color": "#F44336",
        "id": 70,
        "label": "Chapter 12. Fine-Tuning Generation Models",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Chapter 12. Fine-Tuning Generation Models",
         "label": "Chapter:__Entity__",
         "uuid": "1a27313c-93db-48bb-bcec-9360b096c2f5"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#9C27B0",
        "id": 71,
        "label": "Pretraining",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Pretraining",
         "label": "Training_step:__Entity__",
         "uuid": "8a50d5e5-54f6-4696-a65f-f9c294e14223"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9C27B0"
       },
       {
        "color": "#9E9E9E",
        "id": 73,
        "label": "Preference Tuning",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Preference Tuning",
         "label": "Training_step:Fine-tuning:__Entity__:Process",
         "uuid": "f3ea4f1e-657e-469c-8bfe-cfcb9f8a5020"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#9E9E9E"
       },
       {
        "color": "#2196F3",
        "id": 39,
        "label": "Linguistic And Semantic Representations",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Linguistic And Semantic Representations",
         "label": "Representations:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#2196F3"
       },
       {
        "color": "#4CAF50",
        "id": 38,
        "label": "Tokens",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Tokens",
         "label": "Unit:__Entity__"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#4CAF50"
       },
       {
        "color": "#F44336",
        "id": 75,
        "label": "Llm",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Llm",
         "label": "Thing:Person:Language model:Model:Concept:__Entity__",
         "uuid": "828427a5-68b3-446c-8f29-8797afb85c3c"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#F44336"
       },
       {
        "color": "#607D8B",
        "id": 84,
        "label": "Large Datasets",
        "position": [
         0,
         0
        ],
        "properties": {
         "id": "Large Datasets",
         "label": "Data:__Entity__",
         "uuid": "75024517-1e65-43eb-8822-b71f39541058"
        },
        "scale_factor": 1,
        "size": [
         55,
         55
        ],
        "styles": {},
        "type": "#607D8B"
       }
      ],
      "_overview": {
       "enabled": null,
       "overview_set": false
      },
      "_selected_graph": [
       [],
       []
      ],
      "_sidebar": {
       "enabled": false,
       "start_with": null
      },
      "_view_count": null,
      "_view_module": "yfiles-jupyter-graphs",
      "_view_module_version": "^1.10.1",
      "_view_name": "GraphView",
      "layout": "IPY_MODEL_8310731ee65d48faa6771b4240d470ae",
      "tabbable": null,
      "tooltip": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
